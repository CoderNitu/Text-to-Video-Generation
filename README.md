# Text-to-Video-Generation
Generative AI is a rapidly growing field that focuses on developing algorithms that can create content independently, without being explicitly programmed. Text-to-video synthesis is one of the most fascinating applications of this technology, as it allows us to generate videos from simple text prompts. Here I learned how to input a simple text prompt, configure the pre-trained diffusion model by using DiffusionPipeline, and generate a video. 

## Generative Artificial Intelligence (GAI)

Generative artificial intelligence (GAI) is a type of AI that can create new content, such as text, images, music, and videos. GAI models learn the patterns and structure of their input training data and then generate new data with similar characteristics. GAI can learn from existing artifacts to generate new, realistic artifacts that reflect the characteristics of the training data but don't repeat it. Inputs and outputs to GAI models can include text, images, sounds, animation, 3D models, or other types of data.

![Screenshot (195)](https://github.com/CoderNitu/Text-to-Video-Generation/assets/87817227/1c5feeef-0862-4c67-8c40-f28c643b2652)


## Diffusion Models vs GANs

Generative Adversarial Networks (GANs) and Diffusion Models represent two approaches to generative AI. While both aim to generate high-quality samples, they differ in their underlying architectures and training methodologies

 ## 1. Generative Adversarial Networks (GANs): Breathing Life into Synthetic Data
   Generative Adversarial Networks (GANs) were developed by Ian Goodfellow and his team in 2014, which has inspired the field of generative AI. This approach uses two simultaneously 
   trained neural networks, one is the generator used to generate synthetic data (fake data), and the other is the discriminator, which is used to classify whether the input is real 
   (from the training dataset) or fake (generated by the generator). The word adversarial points to the competitive dynamic between the generator and the discriminator, where the 
   generator tries to fool the discriminator by passing fake data. The discriminator's job is to detect the fake data generated by the generator. The competitive nature of GAN training 
   drives the iterative refinement of the generator's output. A loss function is calculated to quantify the difference between the discriminator's predictions and the ground truth 
   labels; the generator minimizes this loss, while the discriminator maximizes it. As training continues, the networks update their parameters based on each other's feedback, gradually 
   enhancing the quality and realism of the generated samples.

 ![gans_gfg-(1)](https://github.com/CoderNitu/Text-to-Video-Generation/assets/87817227/eb063050-7f9c-44f3-9652-6d07d52021e2)
![EXX-Blog-Gan-vs-diffusion-models-2](https://github.com/CoderNitu/Text-to-Video-Generation/assets/87817227/ac778b14-e173-430f-a527-a38ad2720104)

 2. Diffusion Models: An Elegant Journey from Noise to Data
   Diffusion models are generative AI models that create high-resolution data domain samples. They use Gaussian noise (a type of random noise that is often added to the input data, which    helps the diffusion model to generate new data that is similar to the training data, even when the input is not perfect)
   The diffusion Model works using two processes :
   (a) Forward Diffusion process
       The forward diffusion process is a Markov chain that starts from the original data x and ends at a noise sample ε. At each step t, the data is corrupted by adding Gaussian noise 
       to it. The noise level increases as t increases until it reaches 1 at the final step T. At this point, x_T is completely random and independent of x.

    x_t = √(1 – βt) * x(t-1) + √β_t * η_t
     where β_t is the noise level at step t, and η_t is a standard Gaussian random variable. The noise level β_t increases as t increases until it reaches 1 at the final step T. At 
     this point, x_T is completely random and independent of x.
   



 




